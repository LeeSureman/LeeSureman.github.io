---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ## About Me -->
I am a fourth-year PhD student at Fudan University, advised by Prof. [Xipeng Qiu](https://xpqiu.github.io/).  
My research interest focuses on Large Language Models & Retrieval, especially Retrieval-augmented LLM Generation, LLM-augmented Retrieval and LLM's Verifiable Generation.  

[//]: # (Looking for Industry Opportunities, e.g., Research Scientist and Applied Scientist. I'm expected to graduate in June 2025.)
[//]: # (I'm expected to receive my PhD degree in June 2025.   )
***<font color=red>I'm expected to receive my PhD degree in June 2025 and will seek industry opportunities (US / CN) in 2024.</font>***

# Education
- **Fudan University**  
  Ph.D. in Computer Science, 2020.9 - 2025.6 (expected)  
  Advisor: Prof. Xipeng Qiu  
- **Xidian University**  
  B.E. in Computer Science, 2016.9 - 2020.7  
  GPA: 3.9/4.00, Ranking: 3/400  

# Experience
- **Microsoft Research Asia**  
  Advisor: Dr. Yeyun Gong  
  2021.6 - 2022.6

# Publications
\* denotes co-first authors
<!-- $^\dagger$ denotes corresponding author/main advisor -->

Qinyuan Cheng *, ***Xiaonan Li*** *, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, Xipeng Qiu  
[**Unified Active Retrieval for Retrieval Augmented Generation**](https://arxiv.org/pdf/2406.12534)  
Arxiv 2024.6

Xingyu Lu *, ***Xiaonan Li*** *, Qinyuan Cheng, Kai Ding, Xuanjing Huang, Xipeng Qiu  
[**Scaling Laws for Fact Memorization of Large Language Models**](https://arxiv.org/pdf/2406.15720)  
Arxiv 2024.6

***Xiaonan Li*** *, Changtai Zhu *, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu  
[**LLatrieval: LLM-Verified Retrieval for Verifiable Generation**](https://arxiv.org/pdf/2311.07838.pdf)  
NAACL 2024

***Xiaonan Li***, Xipeng Qiu  
[**MoT: Memory-of-Thought Enables ChatGPT to Self-Improve**](https://aclanthology.org/2023.emnlp-main.392.pdf)  
EMNLP 2023  

***Xiaonan Li***, Xipeng Qiu  
[**Finding Support Examples for In-Context Learning**](https://aclanthology.org/2023.findings-emnlp.411.pdf)  
EMNLP 2023 Findings

***Xiaonan Li*** *, Kai Lv *, Hang Yan, Tianyang Lin, Wei Zhu, Yuan Ni, Guotong Xie, Xiaoling Wang, Xipeng Qiu  
[**Unified Demonstration Retriever for In-Context Learning**](https://aclanthology.org/2023.acl-long.256.pdf)  
ACL 2023  

***Xiaonan Li***, Yeyun Gong, Yelong Shen, Xipeng Qiu, Hang Zhang, Bolun Yao, Weizhen Qi, Daxin Jiang, Weizhu Chen, Nan Duan  
[**CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search**](https://aclanthology.org/2022.emnlp-main.187.pdf)  
EMNLP 2022  

***Xiaonan Li*** *, Daya Guo *, Yeyun Gong, Yun Lin, Yelong Shen, Xipeng Qiu, Daxin Jiang, Weizhu Chen, Nan Duan  
[**Soft-Labeled Contrastive Pre-training for Function-level Code Representation**](https://aclanthology.org/2022.findings-emnlp.9.pdf)  
EMNLP 2022 Findings  

***Xiaonan Li***, Yunfan Shao, Tianxiang Sun, Hang Yan, Xipeng Qiu
, Xuanjing Huang  
[**Accelerating BERT Inference for Sequence Labeling via Early-Exit**](https://aclanthology.org/2021.acl-long.16.pdf)  
ACL 2021  

***Xiaonan Li***, Hang Yan, Xipeng Qiu, Xuanjing Huang  
[**FLAT: Chinese NER Using Flat-Lattice Transformer**](https://aclanthology.org/2020.acl-main.611.pdf)  
ACL 2020  


# Awards
National Scholarship in 2020-2021 (Graduate).  
National Scholarship in 2016-2017, 2017-2018 and 2018-2019 (Undergrad).
